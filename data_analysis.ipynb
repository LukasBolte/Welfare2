{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of \"Welfare\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion rate: 1.0\n",
      "Participants who confirmed their answers the first time: 1.0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not float",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 112\u001b[0m\n\u001b[0;32m    109\u001b[0m         WTP_bound \u001b[39m=\u001b[39m (WTP_VALUES[row_choice \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m], WTP_VALUES[row_choice \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m])\n\u001b[0;32m    110\u001b[0m         \u001b[39mreturn\u001b[39;00m WTP_bound\n\u001b[1;32m--> 112\u001b[0m     data[\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mel\u001b[39m}\u001b[39;00m\u001b[39m_wtp3_bounds\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39;49mapply(get_wtp_bound,axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[0;32m    114\u001b[0m \u001b[39m# Function to modify column1\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmodify_column1\u001b[39m(entry, col2_value, col3_value):\n",
      "File \u001b[1;32mc:\\Users\\gonar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:9428\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   9417\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[0;32m   9419\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[0;32m   9420\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m   9421\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9426\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[0;32m   9427\u001b[0m )\n\u001b[1;32m-> 9428\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\gonar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:678\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[0;32m    676\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[1;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\gonar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:798\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 798\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[0;32m    800\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[0;32m    801\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[1;32mc:\\Users\\gonar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:814\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    811\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    812\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[0;32m    813\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m--> 814\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[0;32m    815\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m    816\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m    817\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m    818\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[2], line 95\u001b[0m, in \u001b[0;36mget_wtp_bound\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mif\u001b[39;00m wtp3 \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m wtp3 \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mnan:\n\u001b[0;32m     94\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mWTP is None\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> 95\u001b[0m cutoff \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39;49mloads(wtp3)[\u001b[39m'\u001b[39m\u001b[39mcutoff\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     96\u001b[0m parts \u001b[39m=\u001b[39m cutoff\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     97\u001b[0m side \u001b[39m=\u001b[39m parts[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\gonar\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\json\\__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    338\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(s, (\u001b[39mbytes\u001b[39m, \u001b[39mbytearray\u001b[39m)):\n\u001b[1;32m--> 339\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    340\u001b[0m                         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnot \u001b[39m\u001b[39m{\u001b[39;00ms\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    341\u001b[0m     s \u001b[39m=\u001b[39m s\u001b[39m.\u001b[39mdecode(detect_encoding(s), \u001b[39m'\u001b[39m\u001b[39msurrogatepass\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n",
      "\u001b[1;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not float"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "def load_csv_files(subfolder_name):\n",
    "    notebook_path = os.path.dirname(os.path.abspath('__file__'))\n",
    "    data_folder_path = os.path.join(notebook_path, 'data', subfolder_name)\n",
    "\n",
    "    all_dataframes = []\n",
    "    \n",
    "    # Get a list of all files in the subfolder\n",
    "    files = os.listdir(data_folder_path)\n",
    "\n",
    "    # Loop through each file and load it as a pandas DataFrame\n",
    "    for file in files:\n",
    "        if file.startswith('all_apps_wide') and file.endswith('.csv'):\n",
    "            file_path = os.path.join(data_folder_path, file)\n",
    "            df = pd.read_csv(file_path)\n",
    "            all_dataframes.append(df)\n",
    "\n",
    "    # Concatenate all DataFrames into one, stacking them on top of each other\n",
    "    combined_df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "    return combined_df\n",
    "\n",
    "# Usage:\n",
    "subfolder_name = '2023-08-dummy_data'\n",
    "data = load_csv_files(subfolder_name)\n",
    "\n",
    "# Remove duplicates based on all columns\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "# Restrict to sessions:\n",
    "def restrict_to_sessions(data, session_codes):\n",
    "    return data[data['session.code'].isin(session_codes)]\n",
    "\n",
    "session_codes = ['oczclyt3']\n",
    "if session_codes:\n",
    "    data = restrict_to_sessions(data, session_codes)\n",
    "\n",
    "data.columns = data.columns.str.replace('participant.', '')\n",
    "\n",
    "# List of pages to check against\n",
    "pages_to_exclude = ['Welcome', 'Consent']\n",
    "\n",
    "# Create new columns based on conditions\n",
    "data['started_experiment'] = data['_current_page_name'].apply(lambda x: x not in pages_to_exclude and pd.notna(x))\n",
    "data['finished_experiment'] = data['_current_page_name'].apply(lambda x: x in ['End','Finished'])\n",
    "\n",
    "# Calculate completion rate\n",
    "finished_experiment_count = data['finished_experiment'].sum()\n",
    "started_experiment_count = data['started_experiment'].sum()\n",
    "completion_rate = finished_experiment_count / started_experiment_count\n",
    "\n",
    "print('Completion rate:', completion_rate)\n",
    "\n",
    "# Filter the DataFrame to only include rows where 'finished_experiment' is True\n",
    "data = data[data['finished_experiment']]\n",
    "\n",
    "# Rename columns\n",
    "data['mistakes_cq6'] = data['welfare.1.player.cq6_ambiguous_mistakes']+ data['welfare.1.player.cq6_treatments_mistakes']\n",
    "data.rename(columns={'welfare.1.player.'+cq+'_mistakes': 'mistakes_'+cq for cq in ['cq1','cq2','cq3','cq4','cq5']}, inplace=True)\n",
    "data['mistakes_total'] = data[['mistakes_cq1', 'mistakes_cq2', 'mistakes_cq3', 'mistakes_cq4', 'mistakes_cq5', 'mistakes_cq6']].sum(axis=1)\n",
    "\n",
    "# Calculate share of entries where 'welfare.1.player.confirm' equals 1\n",
    "total_entries = len(data)\n",
    "count_equal_1 = data['welfare.1.player.confirm'].eq(1).sum()\n",
    "share_equal_1 = count_equal_1 / total_entries\n",
    "\n",
    "print('Participants who confirmed their answers the first time:', share_equal_1)\n",
    "\n",
    "# Filter the DataFrame to only include rows where 'finished_experiment' is True\n",
    "data = data[data['finished_experiment']]\n",
    "\n",
    "# Functions to calculate values based on 'welfare.1.player.confirm'\n",
    "def calculate_wtp(row, column_suffix):\n",
    "    return row[f\"welfare.{int(row['welfare.1.player.confirm'])}.player.{column_suffix}\"]\n",
    "\n",
    "for el in ['ES', 'Trad']:\n",
    "    data[f'{el}_wtp'] = data.apply(lambda row: calculate_wtp(row, f'{el}_wtp'), axis=1)\n",
    "    data[f'{el}_wtp2'] = data.apply(lambda row: calculate_wtp(row, f'{el}_wtp2'), axis=1)\n",
    "    data[f'{el}_wtp3'] = data.apply(lambda row: calculate_wtp(row, f'{el}_wtp3'), axis=1)\n",
    "\n",
    "\n",
    "data['original_first'] = data['choices_orders'].isin([1,3,6])\n",
    "\n",
    "# Function to get WTP bounds\n",
    "for el in ['ES', 'Trad']:\n",
    "    def get_wtp_bound(row): \n",
    "        wtp3 = row[f'{el}_wtp3']\n",
    "        if wtp3 is None or wtp3 is np.nan:\n",
    "            return \"WTP is None\"\n",
    "        cutoff = json.loads(wtp3)['cutoff']\n",
    "        parts = cutoff.split(\":\")\n",
    "        side = parts[0]\n",
    "        row_choice = int(parts[1])\n",
    "\n",
    "        if row['original_first']==False:\n",
    "            side = {'left':'right','right':'left'}[side]\n",
    "\n",
    "        if side == \"right\":\n",
    "            row_choice = row_choice - 1\n",
    "            side = \"left\"\n",
    "\n",
    "        WTP_VALUES = [1, 2, 3, 5, 7, 10, 15, 25, 45, 70, 100, 140, 200, float('inf')]\n",
    "\n",
    "        WTP_bound = (WTP_VALUES[row_choice + 1], WTP_VALUES[row_choice + 2])\n",
    "        return WTP_bound\n",
    "    \n",
    "    data[f'{el}_wtp3_bounds'] = data.apply(get_wtp_bound,axis=1)\n",
    "\n",
    "# Function to modify column1\n",
    "def modify_column1(entry, col2_value, col3_value):\n",
    "    if col2_value == 3:\n",
    "        return (0, 0)\n",
    "    elif col2_value == 2:\n",
    "        if col3_value == 1:\n",
    "            return (-1, 0)\n",
    "        elif col3_value == 2:\n",
    "            return (-float('inf'), 0)\n",
    "    elif col2_value == 1:\n",
    "        if col3_value == 2:\n",
    "            return (0, 1)\n",
    "        else: \n",
    "            return entry\n",
    "\n",
    "# Function to calculate average\n",
    "def calculate_average(tup):\n",
    "    if np.inf in tup or -np.inf in tup:\n",
    "        return tup[1] - 10 if tup[0] in [-np.inf,np.inf] else tup[0] + 10\n",
    "    return (tup[0] + tup[1]) / 2\n",
    "\n",
    "# Apply the function to modify 'Column1'\n",
    "for el in ['ES', 'Trad']:\n",
    "    data[f'{el}_wtp3_bounds'] = data.apply(lambda row: modify_column1(row[f'{el}_wtp3_bounds'], row[f'{el}_wtp'], row[f'{el}_wtp2']), axis=1)\n",
    "    data[f'{el}_wtp_point'] = data[f'{el}_wtp3_bounds'].apply(calculate_average)\n",
    "\n",
    "# Calculate the time difference and create a new column 'study_duration'\n",
    "data['study_duration'] = data['end_time'] - data['start_time']\n",
    "\n",
    "# Rename certain columns\n",
    "data.rename(columns={'welfare.2.player.'+el: el for el in ['warhol','arkansas','experience'] + ['feedback'] + ['feedbackDifficulty', 'feedbackUnderstanding', 'feedbackSatisfied', 'feedbackPay']+ ['MPLWhy'] + ['warholWhy','arkansasWhy','experienceWhy']}, inplace=True)\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "output_folder = os.path.join(os.getcwd(), 'output')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "subfolder_path = os.path.join(output_folder, subfolder_name)\n",
    "if not os.path.exists(subfolder_path):\n",
    "    os.makedirs(subfolder_path)\n",
    "\n",
    "# Functions to plot and save CDF, boxplot, and bar chart\n",
    "def plot_and_save_cdf(data, column_names, filename):\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Loop through the list of column names\n",
    "    for column_name in column_names:\n",
    "        # Calculate and plot the stepwise CDF\n",
    "        sorted_data = np.sort(data[column_name])\n",
    "        cdf = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
    "        ax.step(sorted_data, cdf, where='post', label=column_name.capitalize())\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel('Values')\n",
    "    ax.set_ylabel('CDF')\n",
    "    ax.set_title(f'Stepwise Cumulative Distribution Function of Columns')\n",
    "    ax.legend()\n",
    "\n",
    "    # Show the plot\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Save the figure in the subfolder\n",
    "    file_path = os.path.join(subfolder_path, f'stepwise_cdf_{filename}.png')\n",
    "    plt.savefig(file_path)\n",
    "\n",
    "    # Display the plot (optional)\n",
    "    plt.show()\n",
    "\n",
    "def plot_and_save_boxplot(data, column_names, filename):\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Data for boxplot\n",
    "    data_to_plot = [data[column_name] for column_name in column_names]\n",
    "\n",
    "    # Create the boxplot\n",
    "    ax.boxplot(data_to_plot, labels=column_names)\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_ylabel('Values')\n",
    "    ax.set_title(f'Boxplot of Columns')\n",
    "\n",
    "    # Show the plot\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Save the boxplot in the subfolder\n",
    "    file_path = os.path.join(subfolder_path, f'boxplot_{filename}.png')\n",
    "    plt.savefig(file_path)\n",
    "\n",
    "    # Display the plot (optional)\n",
    "    plt.show()\n",
    "\n",
    "def plot_and_save_bar_chart(data, column_name, subfolder_name):\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Data for bar chart\n",
    "    value_counts = data[column_name].value_counts()\n",
    "\n",
    "    # Create the bar chart with frequencies as heights and unique values as x-axis labels\n",
    "    ax.bar(value_counts.index, value_counts)\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel(column_name)\n",
    "    ax.set_ylabel('Frequency')\n",
    "    ax.set_title(f'Bar Chart of {column_name} Frequencies')\n",
    "\n",
    "    # Show the plot\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Save the bar chart in the subfolder\n",
    "    file_path = os.path.join(subfolder_path, f'bar_chart_{column_name}_frequencies.png')\n",
    "    plt.savefig(file_path)\n",
    "\n",
    "    # Display the plot (optional)\n",
    "    plt.show()\n",
    "\n",
    "def plot_and_save_scatter(data, x_column, y_column, subfolder_name):\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Get the counts of each unique pair of (x, y) coordinates\n",
    "    counts = data.groupby([x_column, y_column]).size().reset_index(name='count')\n",
    "\n",
    "    # Merge counts back with the original data to match (x, y) coordinates\n",
    "    merged_data = data.merge(counts, on=[x_column, y_column])\n",
    "\n",
    "    # Scatter plot with increased size for dots with multiple occurrences\n",
    "    ax.scatter(merged_data[x_column], merged_data[y_column], s=merged_data['count'] * 10)  # You can adjust the multiplier (10 in this case) as needed\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel(x_column)\n",
    "    ax.set_ylabel(y_column)\n",
    "    ax.set_title(f'Scatter Plot of {x_column} vs. {y_column}')\n",
    "\n",
    "    # Show the plot\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Create the subfolder if it doesn't exist\n",
    "    subfolder_path = os.path.join('Output', subfolder_name)\n",
    "    if not os.path.exists(subfolder_path):\n",
    "        os.mkdir(subfolder_path)\n",
    "\n",
    "    # Save the scatter plot in the subfolder\n",
    "    file_path = os.path.join(subfolder_path, f'scatter_plot_{x_column}_vs_{y_column}.png')\n",
    "    plt.savefig(file_path)\n",
    "\n",
    "    # Display the plot (optional)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_and_save_scatter_with_condition(data, x_column, y_column, condition_column, condition_x, condition_y, subfolder_name):\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Separate the data based on the condition_column\n",
    "    data_x = data[data[condition_column] == condition_x]\n",
    "    data_y = data[data[condition_column] == condition_y]\n",
    "\n",
    "    # Get the counts of each unique pair of (x, y) coordinates for both conditions\n",
    "    counts_x = data_x.groupby([x_column, y_column]).size().reset_index(name='count')\n",
    "    counts_y = data_y.groupby([x_column, y_column]).size().reset_index(name='count')\n",
    "\n",
    "    # Merge counts back with the original data to match (x, y) coordinates\n",
    "    data_x = data_x.merge(counts_x, on=[x_column, y_column])\n",
    "    data_y = data_y.merge(counts_y, on=[x_column, y_column])\n",
    "\n",
    "    # Scatter plot for condition_x points with increased size for dots with multiple occurrences\n",
    "    ax.scatter(data_x[x_column], data_x[y_column], label=f'{condition_column} = {condition_x}', marker='o', s=data_x['count'] * 20)\n",
    "\n",
    "    # Scatter plot for condition_y points with increased size for dots with multiple occurrences\n",
    "    ax.scatter(data_y[x_column], data_y[y_column], label=f'{condition_column} = {condition_y}', marker='x', s=data_y['count'] * 20)\n",
    "\n",
    "    # Add labels and title\n",
    "    ax.set_xlabel(x_column)\n",
    "    ax.set_ylabel(y_column)\n",
    "    ax.set_title(f'Scatter Plot of {x_column} vs. {y_column}')\n",
    "\n",
    "    # Show the plot\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "\n",
    "    # Create the subfolder if it doesn't exist\n",
    "    subfolder_path = os.path.join('Output', subfolder_name)\n",
    "    if not os.path.exists(subfolder_path):\n",
    "        os.mkdir(subfolder_path)\n",
    "\n",
    "    # Save the scatter plot in the subfolder\n",
    "    file_path = os.path.join(subfolder_path, f'scatter_plot_{x_column}_vs_{y_column}_with_condition.png')\n",
    "    plt.savefig(file_path)\n",
    "\n",
    "    # Display the plot (optional)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Call the functions to plot and save the desired graphs\n",
    "plot_and_save_cdf(data, ['mistakes_total'], 'mistakes_total')\n",
    "plot_and_save_boxplot(data, ['mistakes_total'], 'mistakes_total')\n",
    "plot_and_save_cdf(data, ['Trad_wtp_point','ES_wtp_point'], 'wtp_point')\n",
    "plot_and_save_boxplot(data, ['Trad_wtp_point','ES_wtp_point'], 'wtp_point')\n",
    "plot_and_save_cdf(data,['study_duration'], 'study_duration')\n",
    "plot_and_save_boxplot(data, ['study_duration'], 'study_duration')\n",
    "\n",
    "for el in ['warhol','arkansas','experience']:\n",
    "    plot_and_save_bar_chart(data, el, subfolder_name)\n",
    "\n",
    "for el in ['feedbackDifficulty', 'feedbackUnderstanding', 'feedbackSatisfied', 'feedbackPay']:\n",
    "    plot_and_save_bar_chart(data, el, subfolder_name)\n",
    "\n",
    "for question in ['mistakes_cq1', 'mistakes_cq2', 'mistakes_cq3', 'mistakes_cq4','mistakes_cq5', 'mistakes_cq6']:\n",
    "    # Call the function to plot and save the CDF for question\n",
    "    plot_and_save_cdf(data, [question], subfolder_name)\n",
    "\n",
    "    # Call the function to plot and save the boxplot for question\n",
    "    plot_and_save_boxplot(data, [question], subfolder_name)\n",
    "\n",
    "plot_and_save_scatter(data, 'Trad_wtp_point', 'ES_wtp_point', subfolder_name)\n",
    "plot_and_save_scatter_with_condition(data, 'Trad_wtp_point', 'ES_wtp_point', 'treatment', 'high', 'low', subfolder_name)\n",
    "\n",
    "\n",
    "# Select only the desired columns\n",
    "selected_columns = ['label'] + ['warhol','arkansas','experience'] + ['warholWhy','arkansasWhy','experienceWhy']\n",
    "selected_data = data[selected_columns]\n",
    "\n",
    "# Save the selected data to a CSV file in the 'subfolder'\n",
    "file_path = os.path.join(subfolder_path, 'open_ended.csv')\n",
    "selected_data.to_csv(file_path, index=False)\n",
    "\n",
    "# Select only the desired columns\n",
    "selected_columns = ['label'] +  ['feedback'] + ['feedbackDifficulty', 'feedbackUnderstanding', 'feedbackSatisfied', 'feedbackPay']\n",
    "selected_data = data[selected_columns]\n",
    "\n",
    "# Save the selected data to a CSV file in the 'subfolder'\n",
    "file_path = os.path.join(subfolder_path, 'feedback.csv')\n",
    "selected_data.to_csv(file_path, index=False)\n",
    "\n",
    "# Select only the desired columns\n",
    "selected_columns = ['label'] + ['Trad_wtp3_bounds','ES_wtp3_bounds'] + ['treatment'] + ['mistakes_total']+ ['MPLWhy']\n",
    "selected_data = data[selected_columns]\n",
    "\n",
    "# Save the selected data to a CSV file in the 'subfolder'\n",
    "file_path = os.path.join(subfolder_path, 'MPLWhy.csv')\n",
    "selected_data.to_csv(file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_in_session</th>\n",
       "      <th>code</th>\n",
       "      <th>label</th>\n",
       "      <th>_is_bot</th>\n",
       "      <th>_index_in_pages</th>\n",
       "      <th>_max_page_index</th>\n",
       "      <th>_current_app_name</th>\n",
       "      <th>_current_page_name</th>\n",
       "      <th>time_started_utc</th>\n",
       "      <th>visited</th>\n",
       "      <th>...</th>\n",
       "      <th>mistakes_cq6</th>\n",
       "      <th>mistakes_total</th>\n",
       "      <th>ES_wtp</th>\n",
       "      <th>ES_wtp2</th>\n",
       "      <th>ES_wtp3</th>\n",
       "      <th>Trad_wtp</th>\n",
       "      <th>Trad_wtp2</th>\n",
       "      <th>Trad_wtp3</th>\n",
       "      <th>original_first</th>\n",
       "      <th>ES_wtp3_bounds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1</td>\n",
       "      <td>wzl0pd4l</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>36</td>\n",
       "      <td>welfare</td>\n",
       "      <td>Finished</td>\n",
       "      <td>2023-08-22 19:03:57.050490</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>{\"history\":[],\"cutoff\":\"right:3\"}</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>(5, 7)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_in_session      code  label  _is_bot  _index_in_pages   \n",
       "100              1  wzl0pd4l    NaN        0               37  \\\n",
       "\n",
       "     _max_page_index _current_app_name _current_page_name   \n",
       "100               36           welfare           Finished  \\\n",
       "\n",
       "               time_started_utc  visited  ...  mistakes_cq6  mistakes_total   \n",
       "100  2023-08-22 19:03:57.050490        1  ...             0               0  \\\n",
       "\n",
       "     ES_wtp  ES_wtp2                            ES_wtp3 Trad_wtp  Trad_wtp2   \n",
       "100     1.0      1.0  {\"history\":[],\"cutoff\":\"right:3\"}      2.0        2.0  \\\n",
       "\n",
       "     Trad_wtp3  original_first  ES_wtp3_bounds  \n",
       "100        NaN            True          (5, 7)  \n",
       "\n",
       "[1 rows x 162 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
